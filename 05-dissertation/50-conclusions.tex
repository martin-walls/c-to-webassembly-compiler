\documentclass[00-main.tex]{subfiles}

\begin{document}

\chapter{Conclusions}

In this chapter I summarise what was achieved in the project and reflect on the lessons learnt.
I also offer suggestions of how the work may be taken forwards, if I were to continue the project.

\section{Project Summary}

The project was a success; I met all my success criteria and additionally an extension.
I completed an entire compiler pipeline that transforms a subset of the C language into a WebAssembly binary: the front end, which parses the source code into an \gls{ast}~(\ccref{sec:impl:front end}); the middle end, which transforms the \gls{ast} into my custom \gls{ir}~(\ccref{sec:impl:middle end}); and the back end, which generates a WebAssembly module from the \gls{ir}~(\ccref{sec:impl:back end}).
I provided a Node.js runtime environment that runs the WebAssembly binary and interfaces to the system and standard library~(\ccref{sec:impl:runtime}).

Furthermore, I implemented several optimisations to the program in the middle and back ends of the compiler.
Unreachable procedure elimination reduced the size of generated binaries by pruning unused functions from the call graph~(\ccref{sec:impl:unreachable procedure elimination,sec:eval:unreachable procedure elimination}).
I used tail-call optimisation to drastically reduce the amount of memory used by recursive functions, allowing programs to run that would otherwise crash~(\ccref{sec:impl:tail-call optimisation,sec:eval:tail-call optimisation}).
I created a more optimal stack allocation policy, experimentally tweaking my heuristic to produce significant improvements to programs' memory use~(\ccref{sec:impl:optimised stack allocation,sec:eval:optimised stack allocation}).

My compiler produced correct binaries that maintained the semantics of the source program, when comparing my test programs against GCC\@.
My evaluation showed that my optimisations were successful in improving the performance of programs~(\ccref{sec:eval:optimisations}).
Tail-call optimisation reduced $\bigo{n}$ memory use to $\bigo{1}$ for recursive functions, and my stack allocation policy significantly decreased memory usage.

I gained experience using Rust, including learning idiomatic ways of structuring my code and how to work with the borrow checker to produce memory-safe code.
Throughout the project, I had opportunities to apply theory from the Tripos; ranging from the \emph{Algorithms} course to \emph{Software and Security Engineering}, as well as putting into practice the recent Part II \emph{Optimising Compilers} and \emph{Advanced Computer Architecture} courses.
This allowed my to consolidate and expand my skill set.

The project progressed in line with the timetable set out in the proposal; much of the time, I was slightly ahead of schedule, allowing me to be thorough in my testing.
This left me enough time to successfully implement the stack allocation policy optimisation as an extension.

\section{Further Work}

The most obvious continuation of this project would be to expand the scope to support a larger subset of C.
For example, I could add support for function pointers or linking.

I only implemented a small subset of the standard library.
If I were taking this project further, I would implement more of the standard library, such as the string manipulation functions.
This would provide support for many more source programs.
Notably, I would also implement \CInline{malloc()} and \CInline{free()}, to provide support for heap memory allocation.
In my current memory layout, the heap would grow downwards from high memory.
The runtime environment would keep a list of available memory, from which it would allocate when \CInline{malloc()} is called.
Calling \CInline{free()} would return the memory to the available list.

Furthermore, additional optimisations could be added to the compiler, increasing performance of compiled programs in terms of memory usage, execution speed, and binary code size.
These can be as sophisticated as desired; there are many analyses that can be done at compile-time, including dataflow analysis, constraint-bases analysis, effect systems, and so on.
Pointer analysis---such as Andersen's points-to analysis---can be used to narrow down the possible targets of a pointer~\ccite{andersens-analysis}.
This makes other analyses more precise, for example the clash graph in~\ccref{sec:impl:generating clash graph}.

\end{document}
