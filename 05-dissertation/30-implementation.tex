\documentclass[00-main.tex]{subfiles}

\begin{document}

\chapter{Implementation}

\begin{Comment}
%TC:ignore
Word budget: \textasciitilde 4500--5400 words
%TC:endignore
\end{Comment}

\begin{Comment}
%TC:ignore
Describe what was actually produced.

Describe any design strategies that looked ahead to the testing phase, to demonstrate professional approach
%TC:endignore
\end{Comment}

\section{Repository Overview}

% formatting commands for files/directories in tree
\newcommand{\DTfile}[1]{#1}
\newcommand{\DTdir}[1]{\textbf{#1}/}

\begin{Comment}
%TC:ignore
Don't put github repo url -- it's got my name in it
%TC:endignore
\end{Comment}

I developed my project in a GitHub repository\footnote{\url{https://github.com/martin-walls/cam-part-ii-c-webassembly-compiler}}, ensuring to regularly push to the cloud for backup purposes.
This repository is a monorepo containing both my research and documentation along with my source code.

% - horizontal offset of vertical lines to the right
% - width of horizontal lines sticking out
% - separation between horizontal lines and start of text
% - length of horizontal lines
% - size of connecting dots
\DTsetlength{0.2em}{1em}{0.2em}{0.4pt}{2pt}

\makeatletter
\newcommand \Dotfill {\leavevmode \cleaders \hb@xt@ .7em{\hss .\hss }\hfill \kern \z@}
\makeatother
\renewcommand{\DTcomment}[1]{%
\Dotfill
\rmfamily
\begin{minipage}[t]{8cm}
#1
\end{minipage}
}

\dirtree{%
.1 .
.2 \DTdir{headers} \DTcomment{Header files for the standard library functions I implemented}.
.3 \DTfile{stdio.h}.
.3 {...}.
.2 \DTdir{runtime} \DTcomment{NodeJS runtime environment}.
.3 \DTdir{stdlib} \DTcomment{Implementations of standard library functions in JS}.
.3 \DTfile{run.mjs}.
.3 {...}.
.2 \DTdir{src} \DTcomment{The source code for the compiler, explained below}.
.3 {...}.
.2 \DTdir{tests} \DTcomment{Test specification files}.
.3 {...}.
.2 \DTdir{tools}.
.3 \DTfile{profiler.py} \DTcomment{Code to plot stack usage profiles}.
.3 \DTfile{testsuite.py} \DTcomment{Test runner}.
}

\dirtree{%
.1 \DTdir{src}.
.2 \DTdir{back\_end}.
.2 \DTdir{data\_structures}.
.2 \DTdir{front\_end}.
.2 \DTdir{middle\_end}.
.2 \DTdir{program\_config}.
.2 \DTdir{relooper}.
.2 \DTfile{fmt\_indented.rs}.
.2 \DTfile{id.rs}.
.2 \DTfile{lib.rs}.
.2 \DTfile{main.rs}.
.2 \DTfile{preprocessor.rs}.
}

\begin{Comment}
%TC:ignore
Finish this. Will have to see if it'll be better to have comments on the right of dirs, or to highlight the main structure below
%TC:endignore
\end{Comment}

\section{System Architecture}

\begin{Comment}
%TC:ignore
Compiler Pipeline overview
%TC:endignore
\end{Comment}

\Ccref{fig:project flowchart} describes the high-level structure of the project. The \textcolor{frontendcolor}{front end}, \textcolor{middleendcolor}{middle end}, and \textcolor{backendcolor}{back end} are denoted by colour.

\begin{figure}[H]
  \centering
  \tikzfig{70-figures/01-overview-flowchart}
  \caption{Project structure, highlighting the \textcolor{frontendcolor}{front end}, \textcolor{middleendcolor}{middle end}, and \textcolor{backendcolor}{back end}.}
  \label{fig:project flowchart}
\end{figure}

Each solid box represents a module of the project, transforming the input data representation into the output representation.
The data representations are represented by the dashed boxes.

% The optimisations I implemented in the middle end were unreachable procedure elimination, and tail-call optimisation.
% As an extension to the project, I implemented a more optimal stack allocation policy, as part of the target code generation module.

\section{Front End}

\begin{Comment}
%TC:ignore
Give an overview of the front end
%TC:endignore
\end{Comment}

\subsection{Lexer}

\begin{Comment}
%TC:ignore
C is context-sensitive bcos of typedef defns

Wrote custom lexer to handle this

Implemented as FSM - defined all state transitions

Include FSM diagrams here (main ones here, and put rest in appendix?)
%TC:endignore
\end{Comment}
\begin{Comment}
%TC:ignore
Create rest of the diagrams and put in the appendix.
%TC:endignore
\end{Comment}

The lexer is implemented as a finite state machine. \Ccref{fig:lexing numbers fsm,fig:lexing identifiers fsm} highlight portions of the machine; the remaining state transition diagrams can be found in the appendix.
The diagrams show the input character, as a regular expression, along each transition arrow. (Note: in a slight abuse of regular expression notation, the dot character \texttt{.} represents the literal full stop character, rather than an arbitrary character.)
It is assumed that when no state transition is shown for a particular input,
there is an implicit transition that leads to the single `end of token' state of the machine.
Transition arrows without a prior state are the initial transitions for the first input character.

The finite state machine consumes the source code one character at a time, until the `end of token' state is reached.
Then, the token corresponding to the current state is emitted to the parser.
For tokens such as number literals and identifiers, the lexer appends the input character to a string buffer on each transition, and when the token is complete, the string is stored inside the token.
This gives the parser access to the necessary data about the token, for example the name of the literal.

If, when starting to lex a new token, there is no initial transition corresponding to the input character, then there is no valid token for this input. This raises a lex error, and the compiler will exit.

\Ccref{fig:lexing numbers fsm} shows the finite state machine for lexing number literals. This handles all the different forms of number that C supports: decimal, binary, octal, hexadecimal, and floating point.
(Note: the states leading to the ellipsis token are shown for completeness, even though the token is not a number literal, since they share the starting dot state.)

\begin{figure}[ht]
  \centering
  \tikzfig{70-figures/10-lexer-fsm/00-numbers}
  \caption{Finite state machine for lexing number literals.}
  \label{fig:lexing numbers fsm}
\end{figure}

\Ccref{fig:lexing identifiers fsm} shows the finite state machine for lexing identifiers and typedef names.
This is where we handle the ambiguity introduced into the language by typedef names.
  Every time we consume another character of an identifier, we check whether the current name (which we have stored in the string buffer) matches either a keyword of the language of a typedef name we have encountered this far.
(Keywords are given a higher priority of matching.)
  If a match is found, we move to the corresponding state, represented by the $\epsilon$ transitions (since no input is consumed along these transitions).
When we reach the end of the token, the three states will emit the corresponding token, either an identifier, keyword, or typedef name token respectively.

\begin{figure}[ht]
  \centering
  \tikzfig{70-figures/10-lexer-fsm/01-identifiers}
  \caption{Finite state machine for lexing identifiers.}
  \label{fig:lexing identifiers fsm}
\end{figure}


\subsection{Parser}

\begin{Comment}
%TC:ignore
- wrote parser grammar

Talk about avoiding ambiguities - eg. dangling else - by using Open/Closed statement in grammar

Talk about my \texttt{interpret\_string} implementation, to handle string escaping. Implemented using an iterator.

- created AST representation

Talk about structure of my AST

Talk about how I parsed type specifiers into a standard type representation. Used a bitfield to parse arithmetic types, cos they can be declared in any order.
%TC:endignore
\end{Comment}

\begin{Comment}
%TC:ignore
Describe high-level structure of codebase.

Say that I wrote it from scratch.

-> mention LALRPOP parser generator used for .lalrpop files
%TC:endignore
\end{Comment}

\section{Middle End}

\begin{Comment}
%TC:ignore
Give an overview of the middle end
%TC:endignore
\end{Comment}

\subsection{Intermediate Code Generation}

\begin{Comment}
%TC:ignore
- Defined my own three-address code representation

- for every ast node, defined transformation to 3AC instructions

- created IR data structure to hold instructions + all necessary metadata

- Talk about auto-incrementing IDs - abstraction of the Id trait and generic IdGenerator struct

- handled type information - created data structure to represent possible types

- making sure instructions are type-safe, type converting where necessary - talk about unary/binary conversions, cite the C reference book

- Compile-time evaluation of expressions, eg. for array sizes

- Talk about the Context design pattern I used throughout -- maybe research this and see if it's been done before?
%TC:endignore
\end{Comment}

\subsection{The Relooper Algorithm}

\begin{Comment}
%TC:ignore
cite Emscripten \cite{emscripten}
%TC:endignore
\end{Comment}

\section{Back End: Target Code Generation}


\section{Runtime Environment}

\begin{Comment}
%TC:ignore
- Instantiating wasm module

- stdlib functions skeleton implementation

- arg passing + memory initialisation
%TC:endignore
\end{Comment}

\section{Optimisations}

\subsection{Unreachable Procedure Elimination}

\subsection{Tail-Call Optimisation}

\begin{Comment}
%TC:ignore
Defn of tail-call optimisation

Why do the optimisation
%TC:endignore
\end{Comment}

\section{Summary}

\end{document}
